{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import threading\n",
    "import queue\n",
    "testArray = np.array([[1, 2], [2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [2., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_NMF(a, k, i):\n",
    "    m, n = np.shape(a)\n",
    "    w = np.random.rand(m, k)\n",
    "    h = np.random.rand(k, n)\n",
    "    for _ in range(i):\n",
    "        w = w * (a @ h.T) / (w @ h @ h.T)\n",
    "        h = h * (w.T @ a) / (w.T @ w @ h)\n",
    "    return w @ h\n",
    "\n",
    "simple_NMF(testArray, 2, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [2., 1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def thread_function_w(a, w, h, q, i):\n",
    "    q.put((i, w * (a @ h.T) / (w @ h @ h.T)))\n",
    "\n",
    "def thread_function_h(a, w, h, q, i):\n",
    "    q.put((i, h * (w.T @ a) / (w.T @ w @ h)))\n",
    "\n",
    "def naive_parallel_NMF(a, k, p, numIter):\n",
    "    m, n = np.shape(a)\n",
    "    if m % p > 0:\n",
    "        raise TypeError('Input first dimension not divisible by number of threads')\n",
    "    if n % p > 0:\n",
    "        raise TypeError('Input second dimension not divisible by number of threads')\n",
    "    w = np.random.rand(m, k)\n",
    "    h = np.random.rand(k, n)\n",
    "    a_pieces_1 = np.split(a, p, 0) # cut a into p pieces of shape m/p x n\n",
    "    a_pieces_2 = np.split(a, p, 1) # cut a into p pieces of shape m x n/p\n",
    "    \n",
    "    for _ in range(numIter):\n",
    "        w_pieces = np.split(w, p, 0) # cut w into p pieces of shape m/p x n\n",
    "        w_threads = []\n",
    "        w_queue = queue.Queue()\n",
    "        for j in range(p): # split into p threads to calculate updates for each piece\n",
    "            newThread = threading.Thread(target = thread_function_w, args = (a_pieces_1[j], w_pieces[j], h, w_queue, j))\n",
    "            newThread.start()\n",
    "            w_threads.append(newThread)\n",
    "        for thread in w_threads: # wait for all threads to complete\n",
    "            thread.join()\n",
    "        while not w_queue.empty(): # reconstitute and update w\n",
    "            i, value = w_queue.get()\n",
    "            w_pieces[i] = value\n",
    "        w = np.concatenate(w_pieces, 0)\n",
    "\n",
    "        h_pieces = np.split(h, p, 1) # cut h into p pieces of shape m x n/p\n",
    "        h_threads = []\n",
    "        h_queue = queue.Queue()\n",
    "        for j in range(p): # split into p threads to calculate updates for each piece\n",
    "            newThread = threading.Thread(target = thread_function_h, args = (a_pieces_2[j], w, h_pieces[j], h_queue, j))\n",
    "            newThread.start()\n",
    "            h_threads.append(newThread)\n",
    "        for thread in h_threads: # wait for all threads to complete\n",
    "            thread.join()\n",
    "        while not h_queue.empty(): # reconstitute and update h\n",
    "            i, v = h_queue.get()\n",
    "            h_pieces[i] = v\n",
    "        h = np.concatenate(h_pieces, 1)\n",
    "    return w @ h\n",
    "    \n",
    "naive_parallel_NMF(testArray, 2, 2, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u:\n",
      "[[12.61798205  9.75981838]\n",
      " [ 9.75981838 10.62633052]]\n",
      "\n",
      "v:\n",
      "(64, 2)\n"
     ]
    }
   ],
   "source": [
    "def vertical_thread_function_u(h, q):\n",
    "    q.put(h @ h.T)\n",
    "\n",
    "def vertical_thread_function_v(a, h, q, i):\n",
    "    q.put((i, a @ h.T))\n",
    "\n",
    "def vertical_thread_function_w(w, u, v, q, i, j):\n",
    "    q.put(i, j, w * v / (w @ u))\n",
    "\n",
    "def vertical_thread_function_x(w, q, i, j):\n",
    "    q.put((i, j, w.T @ w))\n",
    "\n",
    "def vertical_thread_function_y(a, w, q, i, j):\n",
    "    q.put((i, j, w.T @ a))\n",
    "\n",
    "def vertical_HPC_NMF(a, k, p_row, p_col, numIter):\n",
    "    m, n = np.shape(a)\n",
    "    if m % (p_row*p_col) > 0:\n",
    "        raise TypeError('Input first dimension not divisible by number of threads')\n",
    "    if n % (p_row*p_col) > 0:\n",
    "        raise TypeError('Input second dimension not divisible by number of threads')\n",
    "    w = np.random.rand(m, k)\n",
    "    h = np.random.rand(k, n)\n",
    "\n",
    "    a_pieces = [np.split(x, p_row, 1) for x in np.split(a, p_row, 0)] # cut a into p_row x p_col pieces of shape m/p_row x n/p_col\n",
    "\n",
    "    for _ in range(numIter):\n",
    "        u = np.zeros((k, k))\n",
    "        h_pieces_u = np.split(h, p_row*p_col, 1) # cut h into p_row*p_col pieces of shape k x n/(p_row*p_col)\n",
    "        threads_u = []\n",
    "        thread_queue_u = queue.Queue()\n",
    "        for i in range(p_row*p_col): # split into p_row*p_col threads to calculate u for each piece\n",
    "            newThread = threading.Thread(target = vertical_thread_function_u, args = (h_pieces_u[i], thread_queue_u))\n",
    "            newThread.start()\n",
    "            threads_u.append(newThread)\n",
    "        for thread in threads_u: # wait for all threads to complete\n",
    "            thread.join()\n",
    "        while not thread_queue_u.empty(): # sum up u\n",
    "            u += thread_queue_u.get()\n",
    "\n",
    "        v_pieces = [np.zeros((int(m/p_row), k)) for _ in range(p_row)] # initialize v cut into p_row pieces of shape m/p_row x k\n",
    "        h_pieces_v = np.split(h, p_row, 1) # cut h into p_row pieces of shape k x n/p_row\n",
    "        threads_v = []\n",
    "        thread_queue_v = queue.Queue()\n",
    "        for i in range(p_row*p_col): # split into p_rpw*p_col threads to calculate updates for each piece\n",
    "            newThread = threading.Thread(target = vertical_thread_function_v, args = (a_pieces[int(i/p_row)][i%p_row], h_pieces_v[i%p_row], thread_queue_v, i))\n",
    "            newThread.start()\n",
    "            threads_v.append(newThread)\n",
    "        for thread in threads_v:\n",
    "            thread.join()\n",
    "        while not thread_queue_v.empty():\n",
    "            i, val = thread_queue_v.get()\n",
    "            v_pieces[i%p_row] += val\n",
    "\n",
    "        x = np.zeros((k, k))\n",
    "        y = np.zeros((k, n))\n",
    "\n",
    "    print(f\"u:\\n{u}\\n\\nv:\\n{np.shape(np.concatenate(v_pieces, 0))}\")\n",
    "    return\n",
    "\n",
    "vertical_HPC_NMF(np.random.rand(64, 32), 2, 4, 2, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce49416ec5583b0c8275b442a1d04bbfd540648d21a9ae0fe7642419cc3fbdff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
